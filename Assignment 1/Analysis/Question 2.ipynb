{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0d871f-957f-4314-94e3-16b9c1c4cf9b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }table.dataframe td { white-space: nowrap !important; }table.dataframe thead th:first-child, table.dataframe tbody th { display: none; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to import pyspark and to define start_spark() and stop_spark()\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import getpass\n",
    "import pandas\n",
    "import pyspark\n",
    "import random\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# Constants used to interact with Azure Blob Storage using the hdfs command or Spark\n",
    "\n",
    "global username\n",
    "\n",
    "username = re.sub('@.*', '', getpass.getuser())\n",
    "\n",
    "global azure_account_name\n",
    "global azure_data_container_name\n",
    "global azure_user_container_name\n",
    "global azure_user_token\n",
    "\n",
    "azure_account_name = \"madsstorage002\"\n",
    "azure_data_container_name = \"campus-data\"\n",
    "azure_user_container_name = \"campus-user\"\n",
    "azure_user_token = r\"sp=racwdl&st=2025-08-01T09:41:33Z&se=2026-12-30T16:56:33Z&spr=https&sv=2024-11-04&sr=c&sig=GzR1hq7EJ0lRHj92oDO1MBNjkc602nrpfB5H8Cl7FFY%3D\"\n",
    "\n",
    "\n",
    "# Functions used below\n",
    "\n",
    "def dict_to_html(d):\n",
    "    \"\"\"Convert a Python dictionary into a two column table for display.\n",
    "    \"\"\"\n",
    "\n",
    "    html = []\n",
    "\n",
    "    html.append(f'<table width=\"100%\" style=\"width:100%; font-family: monospace;\">')\n",
    "    for k, v in d.items():\n",
    "        html.append(f'<tr><td style=\"text-align:left;\">{k}</td><td>{v}</td></tr>')\n",
    "    html.append(f'</table>')\n",
    "\n",
    "    return ''.join(html)\n",
    "\n",
    "\n",
    "def show_as_html(df, n=20):\n",
    "    \"\"\"Leverage existing pandas jupyter integration to show a spark dataframe as html.\n",
    "    \n",
    "    Args:\n",
    "        n (int): number of rows to show (default: 20)\n",
    "    \"\"\"\n",
    "\n",
    "    display(df.limit(n).toPandas())\n",
    "\n",
    "    \n",
    "def display_spark():\n",
    "    \"\"\"Display the status of the active Spark session if one is currently running.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        name = sc.getConf().get(\"spark.app.name\")\n",
    "\n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:green\">active</span></b>, look for <code>{name}</code> under the running applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"http://localhost:{sc.uiWebUrl.split(\":\")[-1]}\" target=\"_blank\">Spark Application UI</a></li>',\n",
    "            f'</ul>',\n",
    "            f'<p><b>Config</b></p>',\n",
    "            dict_to_html(dict(sc.getConf().getAll())),\n",
    "            f'<p><b>Notes</b></p>',\n",
    "            f'<ul>',\n",
    "            f'<li>The spark session <code>spark</code> and spark context <code>sc</code> global variables have been defined by <code>start_spark()</code>.</li>',\n",
    "            f'<li>Please run <code>stop_spark()</code> before closing the notebook or restarting the kernel or kill <code>{name}</code> by hand using the link in the Spark UI.</li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:red\">stopped</span></b>, confirm that <code>{username} (notebook)</code> is under the completed applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "\n",
    "\n",
    "# Functions to start and stop spark\n",
    "\n",
    "def start_spark(executor_instances=2, executor_cores=1, worker_memory=1, master_memory=1):\n",
    "    \"\"\"Start a new Spark session and define globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \n",
    "    Args:\n",
    "        executor_instances (int): number of executors (default: 2)\n",
    "        executor_cores (int): number of cores per executor (default: 1)\n",
    "        worker_memory (float): worker memory (default: 1)\n",
    "        master_memory (float): master memory (default: 1)\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    cores = executor_instances * executor_cores\n",
    "    partitions = cores * 4\n",
    "    port = 4000 + random.randint(1, 999)\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dderby.system.home=/tmp/{username}/spark/\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "        .config(\"spark.executor.instances\", str(executor_instances))\n",
    "        .config(\"spark.executor.cores\", str(executor_cores))\n",
    "        .config(\"spark.cores.max\", str(cores))\n",
    "        .config(\"spark.driver.memory\", f'{master_memory}g')\n",
    "        .config(\"spark.executor.memory\", f'{worker_memory}g')\n",
    "        .config(\"spark.driver.maxResultSize\", \"0\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", str(partitions))\n",
    "        .config(\"spark.kubernetes.container.image\", \"madsregistry001.azurecr.io/hadoop-spark:v3.3.5-openjdk-8\")\n",
    "        .config(\"spark.kubernetes.container.image.pullPolicy\", \"IfNotPresent\")\n",
    "        .config(\"spark.kubernetes.memoryOverheadFactor\", \"0.3\")\n",
    "        .config(\"spark.memory.fraction\", \"0.1\")\n",
    "        .config(f\"fs.azure.sas.{azure_user_container_name}.{azure_account_name}.blob.core.windows.net\",  azure_user_token)\n",
    "        .config(\"spark.app.name\", f\"{username} (notebook)\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    \n",
    "    display_spark()\n",
    "\n",
    "    \n",
    "def stop_spark():\n",
    "    \"\"\"Stop the active Spark session and delete globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        spark.stop()\n",
    "\n",
    "        del spark\n",
    "        del sc\n",
    "\n",
    "    display_spark()\n",
    "\n",
    "\n",
    "# Make css changes to improve spark output readability\n",
    "\n",
    "html = [\n",
    "    '<style>',\n",
    "    'pre { white-space: pre !important; }',\n",
    "    'table.dataframe td { white-space: nowrap !important; }',\n",
    "    'table.dataframe thead th:first-child, table.dataframe tbody th { display: none; }',\n",
    "    '</style>',\n",
    "]\n",
    "display(HTML(''.join(html)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85832872-5393-4ea9-9f6c-6a49c94386ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.azure.sas.campus-user.madsstorage002.blob.core.windows.net\n",
      "Warning: Ignoring non-Spark config property: SPARK_DRIVER_BIND_ADDRESS\n",
      "25/09/12 13:45:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Spark</b></p><p>The spark session is <b><span style=\"color:green\">active</span></b>, look for <code>rsh224 (notebook)</code> under the running applications section in the Spark UI.</p><ul><li><a href=\"http://localhost:4046\" target=\"_blank\">Spark Application UI</a></li></ul><p><b>Config</b></p><table width=\"100%\" style=\"width:100%; font-family: monospace;\"><tr><td style=\"text-align:left;\">spark.dynamicAllocation.enabled</td><td>false</td></tr><tr><td style=\"text-align:left;\">spark.fs.azure.sas.uco-user.madsstorage002.blob.core.windows.net</td><td>\"sp=racwdl&st=2024-09-19T08:00:18Z&se=2025-09-19T16:00:18Z&spr=https&sv=2022-11-02&sr=c&sig=qtg6fCdoFz6k3EJLw7dA8D3D8wN0neAYw8yG4z4Lw2o%3D\"</td></tr><tr><td style=\"text-align:left;\">spark.kubernetes.driver.pod.name</td><td>spark-master-driver</td></tr><tr><td style=\"text-align:left;\">spark.executor.instances</td><td>4</td></tr><tr><td style=\"text-align:left;\">spark.driver.memory</td><td>4g</td></tr><tr><td style=\"text-align:left;\">spark.app.name</td><td>rsh224 (notebook)</td></tr><tr><td style=\"text-align:left;\">spark.fs.azure.sas.campus-user.madsstorage002.blob.core.windows.net</td><td>\"sp=racwdl&st=2024-09-19T08:03:31Z&se=2025-09-19T16:03:31Z&spr=https&sv=2022-11-02&sr=c&sig=kMP%2BsBsRzdVVR8rrg%2BNbDhkRBNs6Q98kYY695XMRFDU%3D\"</td></tr><tr><td style=\"text-align:left;\">spark.kubernetes.container.image.pullPolicy</td><td>IfNotPresent</td></tr><tr><td style=\"text-align:left;\">spark.app.startTime</td><td>1757641536712</td></tr><tr><td style=\"text-align:left;\">spark.sql.shuffle.partitions</td><td>32</td></tr><tr><td style=\"text-align:left;\">spark.kubernetes.namespace</td><td>rsh224</td></tr><tr><td style=\"text-align:left;\">spark.kubernetes.executor.podNamePrefix</td><td>rsh224-notebook-508993993b997804</td></tr><tr><td style=\"text-align:left;\">spark.serializer.objectStreamReset</td><td>100</td></tr><tr><td style=\"text-align:left;\">spark.driver.maxResultSize</td><td>0</td></tr><tr><td style=\"text-align:left;\">spark.submit.deployMode</td><td>client</td></tr><tr><td style=\"text-align:left;\">spark.app.submitTime</td><td>1757641536616</td></tr><tr><td style=\"text-align:left;\">spark.master</td><td>k8s://https://kubernetes.default.svc.cluster.local:443</td></tr><tr><td style=\"text-align:left;\">spark.fs.azure</td><td>org.apache.hadoop.fs.azure.NativeAzureFileSystem</td></tr><tr><td style=\"text-align:left;\">spark.driver.extraJavaOptions</td><td>-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dderby.system.home=/tmp/rsh224/spark/</td></tr><tr><td style=\"text-align:left;\">spark.memory.fraction</td><td>0.1</td></tr><tr><td style=\"text-align:left;\">spark.app.id</td><td>spark-ecdab7385d2a4b179b404ac5118f3577</td></tr><tr><td style=\"text-align:left;\">spark.executor.memory</td><td>4g</td></tr><tr><td style=\"text-align:left;\">spark.executor.id</td><td>driver</td></tr><tr><td style=\"text-align:left;\">spark.kubernetes.executor.container.image</td><td>madsregistry001.azurecr.io/hadoop-spark:v3.3.5-openjdk-8-1.0.16</td></tr><tr><td style=\"text-align:left;\">spark.executor.cores</td><td>2</td></tr><tr><td style=\"text-align:left;\">spark.kubernetes.memoryOverheadFactor</td><td>0.3</td></tr><tr><td style=\"text-align:left;\">spark.driver.host</td><td>spark-master-svc</td></tr><tr><td style=\"text-align:left;\">spark.ui.port</td><td>${env:SPARK_UI_PORT}</td></tr><tr><td style=\"text-align:left;\">spark.kubernetes.container.image</td><td>madsregistry001.azurecr.io/hadoop-spark:v3.3.5-openjdk-8</td></tr><tr><td style=\"text-align:left;\">spark.kubernetes.executor.podTemplateFile</td><td>/opt/spark/conf/executor-pod-template.yaml</td></tr><tr><td style=\"text-align:left;\">fs.azure.sas.campus-user.madsstorage002.blob.core.windows.net</td><td>sp=racwdl&st=2025-08-01T09:41:33Z&se=2026-12-30T16:56:33Z&spr=https&sv=2024-11-04&sr=c&sig=GzR1hq7EJ0lRHj92oDO1MBNjkc602nrpfB5H8Cl7FFY%3D</td></tr><tr><td style=\"text-align:left;\">spark.rdd.compress</td><td>True</td></tr><tr><td style=\"text-align:left;\">spark.executor.extraJavaOptions</td><td>-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false</td></tr><tr><td style=\"text-align:left;\">spark.cores.max</td><td>8</td></tr><tr><td style=\"text-align:left;\">spark.driver.port</td><td>7077</td></tr><tr><td style=\"text-align:left;\">spark.submit.pyFiles</td><td></td></tr><tr><td style=\"text-align:left;\">spark.ui.showConsoleProgress</td><td>true</td></tr></table><p><b>Notes</b></p><ul><li>The spark session <code>spark</code> and spark context <code>sc</code> global variables have been defined by <code>start_spark()</code>.</li><li>Please run <code>stop_spark()</code> before closing the notebook or restarting the kernel or kill <code>rsh224 (notebook)</code> by hand using the link in the Spark UI.</li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to start a spark session in this notebook\n",
    "\n",
    "start_spark(executor_instances=4, executor_cores=2, worker_memory=4, master_memory=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787cdb5d-6b5a-4fe1-8cbe-5ef019d4537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your imports here or insert cells below\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from math import radians, sin, cos, asin, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c52349-b2c1-4ec5-805e-55f9f2fa7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_enriched_path = f'wasbs://{azure_user_container_name}@{azure_account_name}.blob.core.windows.net/{username}/stations-enriched'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e788f883-07f4-4ed2-9ba1-a8a927090a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/12 13:46:28 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/09/12 13:46:43 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/09/12 13:46:58 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/09/12 13:47:13 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/09/12 13:47:28 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n"
     ]
    }
   ],
   "source": [
    "stations_enriched = spark.read.csv(stations_enriched_path, header=True, inferSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22216d88-c0ce-415e-a18f-46acef329d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stations_enriched.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998b459-4eaa-40f4-a78c-0dc7a20a974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_enriched.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f2df2-02ef-4687-9c32-5820c65a71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = stations_enriched.select(\n",
    "    'ID',\n",
    "    F.col('LATITUDE').cast(DoubleType()),\n",
    "    F.col('LONGITUDE').cast(DoubleType()),\n",
    "    'STATION_NAME'\n",
    ")\n",
    "\n",
    "stations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca96f5c-50bd-4b95-aa5e-769bea24a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_nz = stations.filter(F.col('COUNTRY_CODE') == 'NZ').select(\n",
    "    F.col('ID').alias('ID_A'),\n",
    "    F.col('LATITUDE').alias('LAT_A'),\n",
    "    F.col('LONGITUDE').alias('LON_A'),\n",
    "    F.col('STATION_NAME').alias('NAME_A')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ededebab-677c-4b8a-ba97-213cbfb91e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------+-------------------+\n",
      "|ID_A       |LAT_A  |LON_A   |NAME_A             |\n",
      "+-----------+-------+--------+-------------------+\n",
      "|NZ000093994|-29.25 |-177.917|RAOUL ISL/KERMADEC |\n",
      "|NZ000093417|-40.9  |174.983 |PARAPARAUMU AWS    |\n",
      "|NZ000093844|-46.417|168.333 |INVERCARGILL AIRPOR|\n",
      "|NZM00093678|-42.417|173.7   |KAIKOURA           |\n",
      "|NZ000939450|-52.55 |169.167 |CAMPBELL ISLAND AWS|\n",
      "|NZM00093439|-41.333|174.8   |WELLINGTON AERO AWS|\n",
      "|NZM00093929|-50.483|166.3   |ENDERBY ISLAND AWS |\n",
      "|NZ000936150|-42.717|170.983 |HOKITIKA AERODROME |\n",
      "|NZ000093012|-35.1  |173.267 |KAITAIA            |\n",
      "|NZ000093292|-38.65 |177.983 |GISBORNE AERODROME |\n",
      "|NZ000937470|-44.517|169.9   |TARA HILLS         |\n",
      "|NZ000939870|-43.95 |-176.567|CHATHAM ISLANDS AWS|\n",
      "|NZM00093110|-37.0  |174.8   |AUCKLAND AERO AWS  |\n",
      "|NZM00093781|-43.489|172.532 |CHRISTCHURCH INTL  |\n",
      "|NZ000933090|-39.017|174.183 |NEW PLYMOUTH AWS   |\n",
      "+-----------+-------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations_nz.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c403c25-2010-4898-bc42-735242178a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_nz_b = stations_nz.select(\n",
    "    F.col('ID_A').alias('ID_B'),\n",
    "    F.col('LAT_A').alias('LAT_B'),\n",
    "    F.col('LON_A').alias('LON_B'),\n",
    "    F.col('NAME_A').alias('NAME_B')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf8b177b-f777-4d95-bb2e-63e587608561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------+------------------+-----------+-------+--------+-------------------+\n",
      "|       ID_A| LAT_A|   LON_A|            NAME_A|       ID_B|  LAT_B|   LON_B|             NAME_B|\n",
      "+-----------+------+--------+------------------+-----------+-------+--------+-------------------+\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093678|-42.417|   173.7|           KAIKOURA|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000939450| -52.55| 169.167|CAMPBELL ISLAND AWS|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093439|-41.333|   174.8|WELLINGTON AERO AWS|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093929|-50.483|   166.3| ENDERBY ISLAND AWS|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000936150|-42.717| 170.983| HOKITIKA AERODROME|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000937470|-44.517|   169.9|         TARA HILLS|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000939870| -43.95|-176.567|CHATHAM ISLANDS AWS|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093110|  -37.0|   174.8|  AUCKLAND AERO AWS|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093781|-43.489| 172.532|  CHRISTCHURCH INTL|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000933090|-39.017| 174.183|   NEW PLYMOUTH AWS|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000093994| -29.25|-177.917| RAOUL ISL/KERMADEC|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000093844|-46.417| 168.333|INVERCARGILL AIRPOR|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZM00093678|-42.417|   173.7|           KAIKOURA|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000939450| -52.55| 169.167|CAMPBELL ISLAND AWS|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZM00093439|-41.333|   174.8|WELLINGTON AERO AWS|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZM00093929|-50.483|   166.3| ENDERBY ISLAND AWS|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000936150|-42.717| 170.983| HOKITIKA AERODROME|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000937470|-44.517|   169.9|         TARA HILLS|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000939870| -43.95|-176.567|CHATHAM ISLANDS AWS|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZM00093110|  -37.0|   174.8|  AUCKLAND AERO AWS|\n",
      "+-----------+------+--------+------------------+-----------+-------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations_nz_cross = stations_nz.crossJoin(stations_nz_b).where(F.col('ID_A') < F.col('ID_B'))\n",
    "stations_nz_cross.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a17b014-a557-47f8-8dce-659fdc16551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID_A: string (nullable = true)\n",
      " |-- LAT_A: double (nullable = true)\n",
      " |-- LON_A: double (nullable = true)\n",
      " |-- NAME_A: string (nullable = true)\n",
      " |-- ID_B: string (nullable = true)\n",
      " |-- LAT_B: double (nullable = true)\n",
      " |-- LON_B: double (nullable = true)\n",
      " |-- NAME_B: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations_nz_cross.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7178127a-8c50-4ea0-9d50-ec2695e88027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_nz_cross.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e450da-a40f-478c-be7b-c6dac0824ae7",
   "metadata": {},
   "source": [
    "## Answer 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1205a643-0a90-4294-b193-d21fb97f34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_haversine_distance(lat1_d, lon1_d, lat2_d, lon2_d):\n",
    "\n",
    "    # convert degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1_d, lon1_d, lat2_d, lon2_d])\n",
    "    \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Radius of earth in kms\n",
    "    R = 6371.0088\n",
    "\n",
    "    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*(sin(dlon/2)**2)\n",
    "\n",
    "    distance = 2*R*asin(sqrt(a))\n",
    "\n",
    "    return distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77cceea2-8361-4eb7-aa5e-b5067d962054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5570.229873656523"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_haversine_distance(40.7128, 74.0060, 51.5074, 0.1278)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9c4b775-78f5-4129-a474-0b96793e2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_distance_udf = F.udf(get_haversine_distance, DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196f922-8e9b-41dd-98ac-5e485b6696bf",
   "metadata": {},
   "source": [
    "## Answer 2(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "749dcae4-58f1-4419-861f-5f0d6d21325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------+------------------+-----------+-------+--------+-------------------+------------------+\n",
      "|       ID_A| LAT_A|   LON_A|            NAME_A|       ID_B|  LAT_B|   LON_B|             NAME_B|          DISTANCE|\n",
      "+-----------+------+--------+------------------+-----------+-------+--------+-------------------+------------------+\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093678|-42.417|   173.7|           KAIKOURA|1645.5672600919054|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000939450| -52.55| 169.167|CAMPBELL ISLAND AWS| 2799.180360445167|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093439|-41.333|   174.8|WELLINGTON AERO AWS|1495.9438524148266|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093929|-50.483|   166.3| ENDERBY ISLAND AWS| 2705.424733563147|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000936150|-42.717| 170.983| HOKITIKA AERODROME|1796.3643450230413|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000937470|-44.517|   169.9|         TARA HILLS|2008.8889124661578|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000939870| -43.95|-176.567|CHATHAM ISLANDS AWS|1638.9394401113698|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093110|  -37.0|   174.8|  AUCKLAND AERO AWS|1095.8245894257714|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZM00093781|-43.489| 172.532|  CHRISTCHURCH INTL|1796.5588510806892|\n",
      "|NZ000093994|-29.25|-177.917|RAOUL ISL/KERMADEC|NZ000933090|-39.017| 174.183|   NEW PLYMOUTH AWS|1305.7059798030075|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000093994| -29.25|-177.917| RAOUL ISL/KERMADEC|1446.3171962590727|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000093844|-46.417| 168.333|INVERCARGILL AIRPOR|  813.355383439714|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZM00093678|-42.417|   173.7|           KAIKOURA| 199.5298991599465|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000939450| -52.55| 169.167|CAMPBELL ISLAND AWS|1368.0595720805434|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZM00093439|-41.333|   174.8|WELLINGTON AERO AWS|50.529096275802594|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZM00093929|-50.483|   166.3| ENDERBY ISLAND AWS| 1259.152897057575|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000936150|-42.717| 170.983| HOKITIKA AERODROME| 388.1766546518753|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000937470|-44.517|   169.9|         TARA HILLS| 577.9221190655095|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZ000939870| -43.95|-176.567|CHATHAM ISLANDS AWS| 771.5374946402351|\n",
      "|NZ000093417| -40.9| 174.983|   PARAPARAUMU AWS|NZM00093110|  -37.0|   174.8|  AUCKLAND AERO AWS|433.94912994471207|\n",
      "+-----------+------+--------+------------------+-----------+-------+--------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations_nz_distance = stations_nz_cross.withColumn(\n",
    "    'DISTANCE', get_distance_udf(\n",
    "        F.col('LAT_A'),\n",
    "        F.col('LON_A'),\n",
    "        F.col('LAT_B'),\n",
    "        F.col('LON_B')\n",
    "    )\n",
    ")\n",
    "\n",
    "stations_nz_distance.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3bc0ed7e-ff0e-4627-b40b-965d33582128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------+-------------------+-----------+-------+-------+-------------------+------------------+\n",
      "|       ID_A|  LAT_A|  LON_A|             NAME_A|       ID_B|  LAT_B|  LON_B|             NAME_B|          DISTANCE|\n",
      "+-----------+-------+-------+-------------------+-----------+-------+-------+-------------------+------------------+\n",
      "|NZ000093417|  -40.9|174.983|    PARAPARAUMU AWS|NZM00093439|-41.333|  174.8|WELLINGTON AERO AWS|50.529096275802594|\n",
      "|NZM00093439|-41.333|  174.8|WELLINGTON AERO AWS|NZM00093678|-42.417|  173.7|           KAIKOURA|151.07164367845573|\n",
      "|NZ000936150|-42.717|170.983| HOKITIKA AERODROME|NZM00093781|-43.489|172.532|  CHRISTCHURCH INTL|152.25856699117296|\n",
      "|NZM00093678|-42.417|  173.7|           KAIKOURA|NZM00093781|-43.489|172.532|  CHRISTCHURCH INTL|152.45918124327264|\n",
      "|NZ000093417|  -40.9|174.983|    PARAPARAUMU AWS|NZM00093678|-42.417|  173.7|           KAIKOURA| 199.5298991599465|\n",
      "|NZ000936150|-42.717|170.983| HOKITIKA AERODROME|NZ000937470|-44.517|  169.9|         TARA HILLS|218.30932075820422|\n",
      "|NZ000093417|  -40.9|174.983|    PARAPARAUMU AWS|NZ000933090|-39.017|174.183|   NEW PLYMOUTH AWS|220.20009846083798|\n",
      "|NZ000936150|-42.717|170.983| HOKITIKA AERODROME|NZM00093678|-42.417|  173.7|           KAIKOURA|224.98158934362704|\n",
      "|NZ000933090|-39.017|174.183|   NEW PLYMOUTH AWS|NZM00093110|  -37.0|  174.8|  AUCKLAND AERO AWS|230.70117909697746|\n",
      "|NZ000937470|-44.517|  169.9|         TARA HILLS|NZM00093781|-43.489|172.532|  CHRISTCHURCH INTL|  239.530460640367|\n",
      "|NZ000093844|-46.417|168.333|INVERCARGILL AIRPOR|NZ000937470|-44.517|  169.9|         TARA HILLS| 244.0533035309449|\n",
      "|NZ000093012|  -35.1|173.267|            KAITAIA|NZM00093110|  -37.0|  174.8|  AUCKLAND AERO AWS| 252.2390216614383|\n",
      "|NZ000933090|-39.017|174.183|   NEW PLYMOUTH AWS|NZM00093439|-41.333|  174.8|WELLINGTON AERO AWS| 262.8067410376763|\n",
      "|NZM00093439|-41.333|  174.8|WELLINGTON AERO AWS|NZM00093781|-43.489|172.532|  CHRISTCHURCH INTL| 303.5246408806086|\n",
      "|NZ000939450| -52.55|169.167|CAMPBELL ISLAND AWS|NZM00093929|-50.483|  166.3| ENDERBY ISLAND AWS|303.56709672196047|\n",
      "|NZ000093292| -38.65|177.983| GISBORNE AERODROME|NZ000933090|-39.017|174.183|   NEW PLYMOUTH AWS| 331.6425608486817|\n",
      "|NZ000093292| -38.65|177.983| GISBORNE AERODROME|NZM00093110|  -37.0|  174.8|  AUCKLAND AERO AWS| 334.3612806314091|\n",
      "|NZ000936150|-42.717|170.983| HOKITIKA AERODROME|NZM00093439|-41.333|  174.8|WELLINGTON AERO AWS|350.79650667541057|\n",
      "|NZ000093417|  -40.9|174.983|    PARAPARAUMU AWS|NZM00093781|-43.489|172.532|  CHRISTCHURCH INTL| 351.5969045143073|\n",
      "|NZ000093292| -38.65|177.983| GISBORNE AERODROME|NZ000093417|  -40.9|174.983|    PARAPARAUMU AWS| 358.1810412550064|\n",
      "+-----------+-------+-------+-------------------+-----------+-------+-------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations_nz_distance.orderBy(F.col('DISTANCE')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8c3e37f-8c80-4387-b875-35d459d6a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/28 11:50:23 WARN AzureFileSystemThreadPoolExecutor: Disabling threads for Delete operation as thread count 0 is <= 1\n"
     ]
    }
   ],
   "source": [
    "output_path = f'wasbs://{azure_user_container_name}@{azure_account_name}.blob.core.windows.net'\n",
    "output_distance_path = f'{output_path}/rsh224/stations_nz_distance'\n",
    "stations_nz_distance.write.mode('overwrite').option('header', True).csv(output_distance_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11a2f575-4974-40e8-8c5e-dc8e3c1cf96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 items\n",
      "-rw-r--r--   1 rsh224 supergroup          0 2025-08-28 11:50 wasbs://campus-user@madsstorage002.blob.core.windows.net/rsh224/stations_nz_distance/_SUCCESS\n",
      "-rw-r--r--   1 rsh224 supergroup       1153 2025-08-28 11:50 wasbs://campus-user@madsstorage002.blob.core.windows.net/rsh224/stations_nz_distance/part-00000-730257f7-e380-4cf1-a01a-25f97d14ca9c-c000.csv\n",
      "-rw-r--r--   1 rsh224 supergroup       2726 2025-08-28 11:50 wasbs://campus-user@madsstorage002.blob.core.windows.net/rsh224/stations_nz_distance/part-00002-730257f7-e380-4cf1-a01a-25f97d14ca9c-c000.csv\n",
      "-rw-r--r--   1 rsh224 supergroup       1035 2025-08-28 11:50 wasbs://campus-user@madsstorage002.blob.core.windows.net/rsh224/stations_nz_distance/part-00003-730257f7-e380-4cf1-a01a-25f97d14ca9c-c000.csv\n",
      "-rw-r--r--   1 rsh224 supergroup        929 2025-08-28 11:50 wasbs://campus-user@madsstorage002.blob.core.windows.net/rsh224/stations_nz_distance/part-00004-730257f7-e380-4cf1-a01a-25f97d14ca9c-c000.csv\n",
      "-rw-r--r--   1 rsh224 supergroup       2820 2025-08-28 11:50 wasbs://campus-user@madsstorage002.blob.core.windows.net/rsh224/stations_nz_distance/part-00005-730257f7-e380-4cf1-a01a-25f97d14ca9c-c000.csv\n",
      "-rw-r--r--   1 rsh224 supergroup       1819 2025-08-28 11:50 wasbs://campus-user@madsstorage002.blob.core.windows.net/rsh224/stations_nz_distance/part-00006-730257f7-e380-4cf1-a01a-25f97d14ca9c-c000.csv\n",
      "-rw-r--r--   1 rsh224 supergroup       1018 2025-08-28 11:50 wasbs://campus-user@madsstorage002.blob.core.windows.net/rsh224/stations_nz_distance/part-00007-730257f7-e380-4cf1-a01a-25f97d14ca9c-c000.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls {output_path}/rsh224/stations_nz_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0484b39-2b75-4af8-a1de-b1a7a2d19e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_spark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
